{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Different model architectures\n",
    "We want to compare different architectures for a CNN model.\n",
    "While keeping the number of learnable params (and maybe computation cost) constant across models,\n",
    "we try to vary their structure between rather flat and deeper models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80b6fd95c21f0ec5"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from prettytable import PrettyTable"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T09:53:50.291952944Z",
     "start_time": "2023-11-28T09:53:41.848490375Z"
    }
   },
   "id": "ad50a6f170a5eab2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utility\n",
    "Function to count learnable params of torch model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30d9d4b1f90e7579"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params += params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T09:59:27.327831827Z",
     "start_time": "2023-11-28T09:59:27.223758577Z"
    }
   },
   "id": "59c209963f3fd4be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 1 - Standard\n",
    "As a starting point we build the 18 layer plain model from *Deep Residual Learning for Image Recognition*.\n",
    "There the input images have size 112 and convolutions are done on feature maps of sizes 56,28,14,7.\n",
    "\n",
    "Here with have input images of 32x32 and do convolutions on feature maps of sizes 32,16,8,4 in block Conv2, Conv3, Conv4 and Conv5 respectively."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7aaf9d408e8937ad"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class Plain18Layer():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            # Conv1: Prepare by mapping to 16 feature maps\n",
    "            nn.Conv2d(3,8, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Conv2:                                        Learnable params\n",
    "            nn.Conv2d(8,16, kernel_size=3, padding=1, bias=False),     # 8*16*3*3 = 1152\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,16, kernel_size=3, padding=1, bias=False),     # 16*16*3*3 = 2304\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,16, kernel_size=3, padding=1, bias=False),     # 16*16*3*3 = 2304\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,16, kernel_size=3, padding=1, bias=False),     # 16*16*3*3 = 2304\n",
    "            nn.ReLU(),                                                  # --------------------\n",
    "                                                                        # conv2 total = 8064\n",
    "\n",
    "            nn.MaxPool2d(2, 2), # output: 16 x 16 x 16\n",
    "            \n",
    "            # Conv3:                                \n",
    "            nn.Conv2d(16,32, kernel_size=3, padding=1, bias=False),     # 16*32*3*3 = 4608\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),                                                  # --------------------\n",
    "                                                                        # conv3 total = 32256\n",
    "\n",
    "            nn.MaxPool2d(2, 2), # output: 32 x 8 x 8\n",
    "            \n",
    "            # Conv4:\n",
    "            nn.Conv2d(32,64, kernel_size=3, padding=1, bias=False),     # 32*64*3*3 = 18432\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,64, kernel_size=3, padding=1, bias=False),     # 64*64*3*3 = 36864\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,64, kernel_size=3, padding=1, bias=False),     # 64*64*3*3 = 36864\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,64, kernel_size=3, padding=1, bias=False),     # 64*64*3*3 = 36864\n",
    "            nn.ReLU(),                                      # --------------------\n",
    "                                                            # conv4 total = 129024\n",
    "\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 4 x 4\n",
    "            \n",
    "            # Conv5:\n",
    "            nn.Conv2d(64,128, kernel_size=3, padding=1, bias=False),    # 64*128*3*3 = 73728\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False),  # 128*128*3*3 = 147456\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False),  # 128*128*3*3 = 147456\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False),  # 128*128*3*3 = 147456\n",
    "            nn.ReLU(),                                      # --------------------\n",
    "\n",
    "\n",
    "        )\n",
    "        '''\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10))\n",
    "        '''\n",
    "            \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T11:08:47.714258863Z",
     "start_time": "2023-11-28T11:08:47.661400514Z"
    }
   },
   "id": "34d53111ec02683b"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|  Modules  | Parameters |\n",
      "+-----------+------------+\n",
      "|  0.weight |    216     |\n",
      "|  2.weight |    1152    |\n",
      "|  4.weight |    2304    |\n",
      "|  6.weight |    2304    |\n",
      "|  8.weight |    2304    |\n",
      "| 11.weight |    4608    |\n",
      "| 13.weight |    9216    |\n",
      "| 15.weight |    9216    |\n",
      "| 17.weight |    9216    |\n",
      "| 20.weight |   18432    |\n",
      "| 22.weight |   36864    |\n",
      "| 24.weight |   36864    |\n",
      "| 26.weight |   36864    |\n",
      "| 29.weight |   73728    |\n",
      "| 31.weight |   147456   |\n",
      "| 33.weight |   147456   |\n",
      "| 35.weight |   147456   |\n",
      "+-----------+------------+\n",
      "Total Trainable Params: 685656\n"
     ]
    },
    {
     "data": {
      "text/plain": "685656"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_18_layer_net = Plain18Layer().network\n",
    "count_parameters(plain_18_layer_net)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T11:08:48.321722636Z",
     "start_time": "2023-11-28T11:08:48.166628837Z"
    }
   },
   "id": "cb05a3d79209cddd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 2 - Deeper\n",
    "In this model we skip going from 32 to 64 feature maps. Instead we stay with 32 maps for more convolutions and then directly go from 32 to 128.\n",
    "\n",
    "In order to keep models comparable we keep the number of trainable parameters constant. Each block of convolutions from the standard model Conv2,..., Conv5 is replaced by Convolutions, so that the number of learnable parameters within the block is the same as with the standard model.\n",
    "Conv4 now operates on 32 instead of 64 feature maps, therefore we can introduce more convolutions in this block while keeping parameter count the same.\n",
    "The 2 convolution of Conv4_a have as many learnable parameters as the first convolution of Conv4 in standard model.\n",
    "The same is true for Conv4_b,c,d and the second, third, fourth convolution of Conv4 in the standard model.\n",
    "\n",
    "As The first convolution of Conv5 now goes from 32 to 128 feature maps instead of 64 to 128 it has half the parameters. We introduce Conv5_a before the 32 -> 128 step and fill the parameters there."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27b744a4aa7b9d9"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class Plain28Layer():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            # Conv1: Prepare by mapping to 16 feature maps\n",
    "            nn.Conv2d(3,8, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Conv2:                                        Learnable params\n",
    "            nn.Conv2d(8,16, kernel_size=3, padding=1, bias=False),     # 8*16*3*3 = 1152\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,16, kernel_size=3, padding=1, bias=False),     # 16*16*3*3 = 2304\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,16, kernel_size=3, padding=1, bias=False),     # 16*16*3*3 = 2304\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,16, kernel_size=3, padding=1, bias=False),     # 16*16*3*3 = 2304\n",
    "            nn.ReLU(),                                      # --------------------\n",
    "                                                            # conv2 total = 8064\n",
    "\n",
    "            nn.MaxPool2d(2, 2), # output: 16 x 16 x 16\n",
    "\n",
    "            # Conv3:                                \n",
    "            nn.Conv2d(16,32, kernel_size=3, padding=1, bias=False),     # 16*32*3*3 = 4608\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),                                      # --------------------\n",
    "                                                            # conv3 total = 32256\n",
    "\n",
    "            nn.MaxPool2d(2, 2), # output: 32 x 8 x 8\n",
    "\n",
    "            # Conv4_a:\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),                                                  # --------------------\n",
    "                                                                        # conv4_d total = 18432\n",
    "\n",
    "            # Conv4_b:\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),                                      # --------------------\n",
    "                                                            # conv4_b total = 36864\n",
    "            \n",
    "            # Conv4_c:\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),                                      # --------------------\n",
    "                                                            # conv4_c total = 36864\n",
    "\n",
    "            # Conv4_d:\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),                                      # --------------------\n",
    "                                                            # conv4_d total = 36864\n",
    "                                                            # =====================\n",
    "                                                            # conv4 total = 36864 + 36864 + 36864 + 18432 = 129024\n",
    "\n",
    "            nn.MaxPool2d(2, 2), # output: 32 x 4 x 4\n",
    "            \n",
    "            # Conv5_a:\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=3, padding=1, bias=False),     # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32,kernel_size=3, padding=1, bias=False),      # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32,kernel_size=3, padding=1, bias=False),      # 32*32*3*3 = 9216\n",
    "            nn.ReLU(),                                      # -------------------\n",
    "                                                            # conv5_a total = 36864\n",
    "\n",
    "            # Conv5_b:\n",
    "            nn.Conv2d(32,128, kernel_size=3, padding=1, bias=False),    # 32*128*3*3 = 36864\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False),  # 128*128*3*3 = 147456\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False),  # 128*128*3*3 = 147456\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False),  # 128*128*3*3 = 147456\n",
    "            nn.ReLU(),                                      # --------------------\n",
    "                                                            # conv5_b total = 479232\n",
    "                                                            # conv5 total = 36864 + 479232 = 516096\n",
    "        )\n",
    "        '''\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10))\n",
    "        '''\n",
    "\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T11:14:12.995714647Z",
     "start_time": "2023-11-28T11:14:12.944974723Z"
    }
   },
   "id": "3ef7c7019d4287e8"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|  Modules  | Parameters |\n",
      "+-----------+------------+\n",
      "|  0.weight |    216     |\n",
      "|  2.weight |    1152    |\n",
      "|  4.weight |    2304    |\n",
      "|  6.weight |    2304    |\n",
      "|  8.weight |    2304    |\n",
      "| 11.weight |    4608    |\n",
      "| 13.weight |    9216    |\n",
      "| 15.weight |    9216    |\n",
      "| 17.weight |    9216    |\n",
      "| 20.weight |    9216    |\n",
      "| 22.weight |    9216    |\n",
      "| 24.weight |    9216    |\n",
      "| 26.weight |    9216    |\n",
      "| 28.weight |    9216    |\n",
      "| 30.weight |    9216    |\n",
      "| 32.weight |    9216    |\n",
      "| 34.weight |    9216    |\n",
      "| 36.weight |    9216    |\n",
      "| 38.weight |    9216    |\n",
      "| 40.weight |    9216    |\n",
      "| 42.weight |    9216    |\n",
      "| 44.weight |    9216    |\n",
      "| 46.weight |    9216    |\n",
      "| 49.weight |    9216    |\n",
      "| 51.weight |    9216    |\n",
      "| 53.weight |    9216    |\n",
      "| 55.weight |    9216    |\n",
      "| 57.weight |   36864    |\n",
      "| 59.weight |   147456   |\n",
      "| 61.weight |   147456   |\n",
      "| 63.weight |   147456   |\n",
      "+-----------+------------+\n",
      "Total Trainable Params: 685656\n"
     ]
    },
    {
     "data": {
      "text/plain": "685656"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_28_layer_net = Plain28Layer().network\n",
    "count_parameters(plain_28_layer_net)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T11:09:06.611336521Z",
     "start_time": "2023-11-28T11:09:06.519131107Z"
    }
   },
   "id": "1579e7498b3cf45c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "=> Teh convolutional layers of both models have 685.656 learnable parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fccabb6019c01c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9a571194b14976b7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
