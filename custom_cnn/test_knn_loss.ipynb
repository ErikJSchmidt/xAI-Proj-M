{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from knn_loss import KNNLoss\n",
    "import utility_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regen_rand():\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a = torch.tensor([[2.0], [3.0], [4.0]])\n",
    "tensor_b = torch.tensor([[0.0], [0.0], [0.0]])\n",
    "tensor_c = torch.tensor([[-2.0], [-3.0], [-4.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors = [tensor_a, tensor_b, tensor_c]\n",
    "stack = torch.stack(tensors)\n",
    "torch.mean(stack, dim = 0)\n",
    "# stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass = torch.randn(256, 128, 1)\n",
    "labels = torch.rand(256, 1, 1)\n",
    "labels *= 9\n",
    "labels = torch.absolute(labels)\n",
    "labels = torch.round(labels)\n",
    "\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "classes_tensor = torch.tensor(classes)\n",
    "classes_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = KNNLoss(classes_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap = KNNLoss(classes_tensor)\n",
    "# div_loss = wrap.divergence_loss(forward_pass, labels)\n",
    "# print(div_loss)\n",
    "# centroids = wrap.get_centroids()\n",
    "# print(centroids.shape)\n",
    "# conv_loss = wrap.convergence_loss(forward_pass, labels)\n",
    "# print(conv_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `# Calculate Current Centroids` section seem to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forward_pass[0])\n",
    "# print(forward_pass[1])\n",
    "\n",
    "# a = forward_pass[0]\n",
    "# b = forward_pass[1]\n",
    "\n",
    "# cos = torch.nn.CosineSimilarity(dim = 0)\n",
    "# wrap.cosine_similarity(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(wrap.get_centroids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_pass = utility_functions.to_device(torch.rand(256, 128, requires_grad=True), 'mps')\n",
    "labels = utility_functions.to_device(torch.rand(256, 1, requires_grad=True), 'mps').mul(9).absolute().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9., device='mps:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(labels.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9077, -0.8776, -0.6546,  ...,  0.2622, -1.0312,  0.3742],\n",
      "        [-0.1276,  1.3103, -0.1642,  ...,  0.0772, -0.6628,  0.4404],\n",
      "        [ 0.0063, -0.4420, -0.4909,  ..., -1.1859, -3.0863, -1.5780],\n",
      "        ...,\n",
      "        [ 0.6508, -0.5801, -0.1529,  ...,  1.1007, -1.4945, -1.4390],\n",
      "        [ 0.3862, -0.3072,  0.0357,  ...,  0.3272, -1.3294,  1.3311],\n",
      "        [ 0.8818,  0.9127,  1.1314,  ..., -0.1038,  0.2508,  1.2267]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "debug_1 = utility_functions.to_device(torch.randn(len(classes_tensor), forward_pass.shape[1]), wrap.device)\n",
    "print(debug_1)\n",
    "wrap.centroids = debug_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5220, 0.4923, 0.2852,  ..., 0.4269, 0.3404, 0.4733],\n",
      "        [0.4729, 0.4295, 0.5457,  ..., 0.4143, 0.5035, 0.4679],\n",
      "        [0.5379, 0.5190, 0.4447,  ..., 0.4237, 0.3033, 0.3978],\n",
      "        ...,\n",
      "        [0.4881, 0.4932, 0.4796,  ..., 0.5118, 0.4787, 0.4030],\n",
      "        [0.3897, 0.4883, 0.5108,  ..., 0.4439, 0.4207, 0.4057],\n",
      "        [0.4803, 0.4497, 0.3725,  ..., 0.4017, 0.5161, 0.6252]],\n",
      "       device='mps:0', grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "c = []\n",
    "for _c in wrap.classes:\n",
    "    class_l = [wrap.centroids[_c].detach()]\n",
    "    for inp, tar in zip(forward_pass, labels):\n",
    "        if int(tar) == _c:\n",
    "            class_l.append(inp)\n",
    "    stacked_t = torch.stack(class_l)\n",
    "    c.append(torch.mean(stacked_t, dim = 0))\n",
    "wrap.centroids = torch.stack(c)\n",
    "print(wrap.centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9784, device='mps:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "d = []\n",
    "for centroid_a in wrap.centroids:\n",
    "    local_d = []    # for each centroid collect distances to other centroids in a list. This list should be ALWAYS be 9 elements long\n",
    "    for centroid_b in wrap.centroids:\n",
    "        if not torch.equal(centroid_a, centroid_b):\n",
    "            local_d.append(wrap.cosine_similarity(centroid_a, centroid_b))\n",
    "    local_t = torch.stack(local_d)\n",
    "    d.append(torch.mean(local_t))\n",
    "wrap.mean_centroid_distance = torch.stack(d).abs().mean()\n",
    "print(wrap.mean_centroid_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_d = []\n",
    "for inp, tar in zip(forward_pass, labels):\n",
    "    label = int(tar)\n",
    "    corresponding_centroid = wrap.centroids[label].detach()\n",
    "    instance_d.append(wrap.euclidean_distance(inp, corresponding_centroid))\n",
    "d = torch.mul(torch.stack(instance_d), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence = torch.mean(d)\n",
    "uniformity = torch.std(d)\n",
    "divergence = torch.div(1, torch.sub(1, wrap.mean_centroid_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2234, device='mps:0', grad_fn=<MeanBackward0>) tensor(0.1345, device='mps:0', grad_fn=<StdBackward0>) tensor(43.5569, device='mps:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    convergence,\n",
    "    uniformity,\n",
    "    divergence\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Now the Ratio doesn't make sense anymore..._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(146.2589, device='mps:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.mul(divergence, convergence.add(uniformity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [utility_functions.to_device(torch.rand(256, 128, requires_grad=True), 'mps') for i in range(195)]\n",
    "targets = [utility_functions.to_device(torch.rand(256, 1, requires_grad=True), 'mps').mul(9).absolute().round() for i in range(195)]\n",
    "\n",
    "loss = KNNLoss(classes_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [utility_functions.to_device(torch.rand(256, 128, requires_grad=True), 'mps') for i in range(64)]\n",
    "targets = [utility_functions.to_device(torch.rand(256, 1, requires_grad=True), 'mps').mul(9).absolute().round() for i in range(64)]\n",
    "\n",
    "loss = KNNLoss(classes_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n",
      "tensor(nan, device='mps:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m, target \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inputs, targets):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_renewed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/xAI-Proj/xAI-Proj-M/custom_cnn/knn_loss.py:28\u001b[0m, in \u001b[0;36mKNNLoss.loss_renewed\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_renewed\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor, target: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_divergence_renewed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# After calling this method, self.centroids will always have shape[0]==len(self.classes)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Calculate mean cosine similarities between centroids\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     d \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/xAI-Proj/xAI-Proj-M/custom_cnn/knn_loss.py:410\u001b[0m, in \u001b[0;36mKNNLoss.prep_divergence_renewed\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    408\u001b[0m class_tensors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroids[_class]\u001b[38;5;241m.\u001b[39mdetach()]                \u001b[38;5;66;03m# The first value in the class tensors is the old centroid. This has very little impact but makes sure that the list is never empty.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inp, tar \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28minput\u001b[39m, target):\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtar\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m _class:\n\u001b[1;32m    411\u001b[0m         class_tensors\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m    412\u001b[0m stacked_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(class_tensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for input, target in zip(inputs, targets):\n",
    "    print(\n",
    "        loss.loss_renewed(input, target)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
